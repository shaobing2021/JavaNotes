## 优化目的

### **避免出现页面访问错误**

* 由于数据库连接timeout产生页面5xx错误
* 由于慢查询造成页面无法加载
* 由于阻塞造成数据无法提交

### 增加数据库的稳定性

* 很多数据库问题都是由于低效的查询导致

### 优化用户体验

* 流畅页面的访问速度
* 良好的网站功能体验

### 步骤

* Sql及索引
* 数据库表结构
* 系统配置
* 硬件

**从上到下, 成本依次增大, 效果依次降低.**

## SQL语句优化

**慢查询**

如何发现有问题的SQL？

使用mysql慢查询日志对有效率问题的SQL进行监控

```cmd
//查看慢查询日志是否开启
show variables like 'slow_query_log';

//查看慢查询日志存储位置
show variables like 'slow_query_log_file';

//开启慢查询日志
set global slow_query_log=on;

//指定慢查询日志存储位置
set global show_query_log_file='/var/lib/mysql/homestead-slow.log';

//记录没有使用索引的sql
set global log_queries_not_using_indexes=on;

//记录查询超过1s的sql
set global long_query_time=1;
```

慢查询日志所包含的内容：

```cmd
#User@Host:root[root] @localhost[]//执行sql的主机信息
#Query_time:0.0000024 Lock_time:0.00 Rows_sent:0 Rows_esamined:0//sql的执行信息
SET timestamp=1402389324//sql执行时间
select * from store; //sql的内容
```

**MySQL慢查询日志分析工具之mysqldumpslow（mysql官方）**

安装完MySQL后，默认就带了mysqldumpslow，很常用的一个工具。

```cmd
//查看参数列表
mysqldumpslow -h

//分析慢查询日志中前三条比较慢的sql
mysqldumpslow -t 3 /var/lib/mysql/homestead-slow.log | more 

//输出样式效果
Count:1 Time:0.00s Lock=0.00s Rows=10.0
root[rppt]@localhost
select * from store
```

**MySQL慢查询日志分析工具之pt-query-digest**

分析结果比mysqldumpslow更详细全面

```cmd
//输出到文件
pt-query-digest slow-log > slow_log.report

//输出到数据表
pt-query-digest slow.log -review \
	h=127.0.0.1,D=test,p=root,P=3306,u=root,t=query_review \
	--create-reviewtable \
	--review-history t=hostname_slow
```

基本使用

```cmd
//查看参数列表
pt-query-digest --help

//分析慢查询日志中前三条比较慢的sql
pt-query-digest /var/lib/mysql/homestead-slow.log | more 

//输出分为三部分
1.显示除了日志的时间范围，以及总的sql数量和不同的sql数量
2.Response Time:响应时间占比 Calls:sql执行次数
3.sql的具体日志
```

如何通过慢查询日志发现有问题的SQL？

```cmd
1.查询次数多且每次查询占用时间长的SQL
通常为pt-query-digest分析的前几个查询

2.IO大的SQL（数据库主要瓶颈出现在IO层次）
注意pt-query-digest分析中的Rows examine项

3.未命中索引的SQL
注意pt-query-digest分析中的Rows examine和Rows Send的对比
```

通过explain查询和分析SQL的执行计划

```
explain select customer_id,,first_name,last_name from customer;
```

| id   | select_type | table     | type                                     | possible_keys         | key               | key_len              | ref              | rows               | Extra                            |
| ---- | ----------- | --------- | ---------------------------------------- | --------------------- | ----------------- | -------------------- | ---------------- | ------------------ | -------------------------------- |
| 1    | SIMPLE      | customer  | ALL                                      | NULL                  | NULL              | NULL                 | NULL             | 671                |                                  |
|      |             | 该数据关于哪张表。 | 示连接使用了何种类型。从好到差const,eq_reg,ref,range,index和ALL。 | 可能应用在该表的索引，空，没有可能的索引。 | 实际使用的索引。空，没有使用索引。 | 使用的索引长度。不损失精度下，越短越好。 | 显示索引的哪一列被使用了，常数。 | mysql认为必须检查的数据的行数。 | 注意：Using filesort,Using tempoary |

Count()和Max()的优化

```cmd
//查询最后支付时间--优化max()函数
explain select max(payment_date) from payment;
create index idx_paydate on payment(payment_data);//给payment_date建立索引(覆盖索引)

//在一条SQL中同时查出2006年和2007年电影的数量--优化Count()函数
select count(release_year='2006' or null) as '2006年电影数量'，count(release_year='2007' or null) as '2007年电影数量' from film;
//有关count()函数
https://blog.csdn.net/wendychiang1991/article/details/70909958/
```

子查询优化

```cmd
通常情况下，需要把子查询优化为join查询，但在优化时要注意关联键是否有一对多的关系，要注意重复数据。(distinct去重)
//查询sandra出演的所有影片
explain select title,release_year,LENGTH from film
where film_id in (
select film_id from film_actor where actor_id in (
select actor_id from actor where first_name='sandra'));
```

group by的优化

```cmd
//改前 临时表
explain select actor.first_name,actor_last_name,count(*) from sakila.film_actor
inner join sakila.actor USING(actor_id)
group by film_actor.actor_id;
//改后 结合子查询 索引
explain select actor.first_name,actor.last_name,c.cnt from sakila.film_actor
inner join (
select actor_id,count(*) as cnt from sakila.film_actor group by actor_id) as c USING(actor_id);
```

limit优化

```cmd
limit常用于分页处理，时常会伴随order by 从句使用，因此大多时候会使用Filesorts这样会造成大量的IO问题。
//文件排序，IO大
explain select film_id,description from sakila.film order by title limit 50,5;
1.优化：使用有索引的列或主键进行order by操作（order by film_id）
2.记录上次返回的主键，在下次查询的时候用主键过滤，避免了数据量大时扫描过多的记录
select film_id,description from sakila.film where film_if>55 and film_id<=60 order by film_id limit 1,5; 
页数越大，IO越大
```

#### 索引优化

如何选择合适的列建立索引？

```
1.在where从句，group by从句，order by从句，on从句中出现的列(select)
2.索引字段越小越好(表每页数据才会更多，IO效率会更高)
3.离散度大的列放到联合索引的前面
select * from payment where staff_id=2 and customer_id=584;
index(staff_id,customer_id)好？还是index(customer_id,staff_id)好？
由于customer_id的离散度更大(重复率小,可选择性更大)，所以应该使用index(customer_id,staff_id)
```

索引优化SQL的方法

索引的维护及优化--重复及冗余索引

```
冗余索引是指多个索引的前缀列相同，或是在联合索引中包含了主键的索引。如下：key(name,id)就是一个冗余索引
create table test(
id int not null primary key,
name varchar(10) not null,
key(name,id)
)engine=innodb;
//可以删除冗余索引，达到优化效果。

使用pt-duplicate-key-checker工具检查重复及冗余索引
pt-duplicate-key-checker \
-uroot \
-p '' \
-h 127.0.0.1
```

索引维护的方法--删除不用索引

```
目前mysql中还没有记录索引的使用情况，但是在PerconMySQL和MariaDB中可通过INDEX_STATISTICS表来查看哪些索引未使用，但在mysql中目前只能通过慢查日志配合pt-index-usage工具来进行索引使用情况分析。
pt-index-usage \
	-uroot -p'' \
	mysql-slow.log
```

#### 数据库表结构优化

1、选择**合适**的数据类型

```
1.使用可以存下你的数据的最小的数据类型
2.使用简单的数据类型。int要比varchar类型在mysql处理上更简单
3.尽可能的使用not null定义字段
4.尽量少用text类型，非用不可时最好考虑分表
*使用int来存储日志时间，利用FROM_UNIXTINE()(得到日期),UNIX_TIMESTAMP()(得到时间戳)两个函数来进行转换
*使用bigint来存ip地址，利用INET_ATON(),INET_NTOA()两个函数来进行转换
```

2、表的范式化和反范式化

**范式化**是指数据库设计的规范，目前说到范式化一般是指第三设计范式，也就是要求数据表中不存在非关键字段对任意候选关键字段的传递函数依赖则符合第三范式。

```
不符合第三范式要求的表存在下列问题：
1.数据冗余：（分类，分类描述）对于每一个商品都会进行记录
2.数据的插入异常
3.数据的更新异常
4.数据的删除异常
```

**反范式化**是指为了查询效率的考虑把原本符合第三范式的表适当的增加冗余，以达到优化查询的目的，反范式化是一种以空间来换取时间的操作。

3、表的拆分

垂直拆分

```
所谓的垂直拆分，就是把原来一个有很多列的表拆分成多个表，这解决了表的宽度问题。通常垂直拆分可以按以下原则进行：
1.把不常用的字段单独存放到一个表中
2.把大字段独立存放到一个表中
3.把经常一起使用的字段放到一起
```

水平拆分

```
表的水平拆分是为了解决单表的数据量过大的问题，水平拆分的表每一个表的结构都是完全一致的。
常用的水平拆分方法为：
1.对id进行hash运算，如果要拆分成5个表则使用mod(id,5)去除0-4个值
2.针对不同的hashID把数据存到不同的表中
```

#### 系统配置优化

1、操作系统配置优化

数据库是基于操作系统的，目前大多数mysql都是安装在Linux系统之上，所以对于操作系统的一些参数配置也会影响到MYSQL的性能。

```
网络方面的配置，要修改/etc/stysctl.conf文件
#增加tcp支持的队列数
net.ipv4.tcp_max_syn_backlog = 65535
#减少断开链接是，资源回收
net.ipv4.tcp_max_tw_buckets = 8000
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_tw_recycle = 1
net.ipv4.tcp_fin_timeout = 10

打开文件数的限制，可以使用ulimit -a 查看目录的各位限制，可以修改/etcsecurity/limitsconf文件，增加一下内容以修改打开文件数量的限制
*soft nofile 65535
*hard nofile 65535
除此之外最好在mysql服务器上关闭iptables，selinux等防火墙软件。
```

2、MySQL数据库优化

MySQL配置文件

```
mysql可以通过启动时指定配置参数和使用配置文件两种方法进行配置，在大数情况下配置文件位于/etc/my.cnf或是/etc/mysql/my.cnf在windows系统配置文件可以是位于C:/windows/my.ini文件，mysql查找配置文件的顺序可以通过一下方法获得
/usr/sbin/mysqld --verbose --help | grep -A 1 ' Default options '
```

MySQL配置文件--常用参数说明

```
1.innodb_buffer_pool_size >= total MB
非常重要的一个参数，用于配置innodb的缓冲池，如果数据库中只有innodb表，则推荐配置量为总内存的75%

2.innodb_buffer_pool__instances
MySQL5.5中新增加参数，可以控制缓冲池的个数，默认情况下只有一个缓冲池。

3.innodb_log_buffer_size
innodb log缓冲的大小，由于日志最长每秒钟就会刷新所以一般不用太大。

4.innodb_flush_log_at_trx_commit
关键参数，对innodb的IO效率影响很大。默认值为1，可取0，1，2三个值，一般建议为2，但如果数据安全性要求比较高则使用默认值1.

5.innodb_read_io_threads   innodb_write_io_threads
以上两个参数决定了Innodb读写的IO进程数，默认为4.

6.innodb_file_per_table
关键参数，控制innodb每一个表使用独立的表空间，默认为off，也就是所有表都会建立在共享表空间中。

7.innodb_stats_on_metadata
决定了mysql在什么情况下会刷新innodb表的统计信息。
```

3、第三方配置工具

🔗链接地址：https://tools.percona.com/wizard

#### 服务器硬件优化

如何选择cpu？

```
1.mysql有一些工作只能使用到单核cpu，Replicate,SQL...
2.mysql对cpu核数的支持并不是越多越快。mysql5.5使用的服务器不要超过30核
```

磁盘IO优化

```
常用RAID级别简介
RAID0：也称条带，就是把多个磁盘链接成一个硬盘使用，这个级别IO最好
RAID1：也称镜像，要求至少有两个磁盘，每组磁盘存储的数据相同
RAID5：也是把多个硬盘合并成一个逻辑盘使用，数据读写时会建立奇偶校验信息，分别存储在不同磁盘上。
RAID1+0：就是RAID1和RAID0的结合。同时具备两个级别的优缺点。一般建议数据库使用这个级别。

SNA和NAT是否适合数据库？
1.常用于高可用解决方案
2.顺序读写效率很高，但是随机读写不如人意
3.数据库随机读写比率很高
```



## 1.Sql优化步骤

> 当面对一个有 SQL 性能问题的数据库时，我们应该从何处入手来进行系统的分析，使得能 够尽快定位问题SQL并尽快解决问题

本文属于[SQL 优化](https://blog.csdn.net/qq_39268193/article/details/98491922)系列篇

### 1.通过show status命令了解各种SQL的执行频率

`MySQL`客户端连接成功后，通过 `show [session|global]status` 命令可以提供服务器状态信息，也可以在操作系统上使用`mysqladmin extended-status` 命令获得这些消息。`show [session|global] status` 可以根据需要加上参数“`session`”或者“`global`”来显示`session`级（当前连接）的统计结果和`global`级（自数据库上次启动至今）的统计结果。如果不写，默认使用参数是“`session`” 。

下面的命令显示了当前`session`中所有统计参数的值：

```mysql
mysql> show status like 'Com_%'; 
+--------------------------+-------+ 
| Variable_name            | Value | 
+--------------------------+-------+ 
| Com_admin_commands       | 0     | 
| Com_alter_db             | 0     | 
| Com_alter_event          | 0     | 
| Com_alter_table          | 0     | 
| Com_analyze              | 0     | 
| Com_backup_table         | 0     | 
| Com_begin                | 0     | 
| Com_change_db            | 1     | 
| Com_change_master        | 0     | 
| Com_check                | 0     | 
| Com_checksum             | 0     | 
| Com_commit               | 0     | 
...... 
1234567891011121314151617
```

`Com_xxx` 表示每个 `xxx`语句执行的次数，我们通常比较关心的是以下几个统计参数。

- `Com_select`：执行 `select` 操作的次数，一次查询只累加 `1`。
- `Com_insert`： 执行 `INSERT` 操作的次数， 对于批量插入的 `INSERT` 操作， 只累加一次。
- `Com_update`：执行 `UPDATE` 操作的次数。
- `Com_delete`：执行 `DELETE` 操作的次数。

上面这些参数对于所有存储引擎的表操作都会进行累计。下面这几个参数只是针对 `InnoDB` 存储引擎的，累加的算法也略有不同。

- `Innodb_rows_read`：`select` 查询返回的行数。
- `Innodb_rows_inserted`：执行 `INSERT` 操作插入的行数。
- `Innodb_rows_updated`：执行 `UPDATE` 操作更新的行数。
- `Innodb_rows_deleted`：执行 `DELETE` 操作删除的行数。

通过以上几个参数，可以很容易地了解当前数据库的应用是以插入更新为主还是以查询 操作为主，以及各种类型的 `SQL` 大致的执行比例是多少。对于更新操作的计数，是对执行次数的计数，不论提交还是回滚都会进行累加。

对于事务型的应用， 通过`Com_commit`和`Com_rollback`可以了解事务提交和回滚的情况， 对于回滚操作非常频繁的数据库，可能意味着应用编写存在问题。

此外，以下几个参数便于用户了解数据库的基本情况。

- `Connections`：试图连接 `MySQL` 服务器的次数。
- `Uptime`：服务器工作时间。
- `Slow_queries`：慢查询的次数。

### 2.定位执行效率较低的 SQL 语句

可以通过以下两种方式定位执行效率较低的 `SQL` 语句。

- 通过慢查询日志定位那些执行效率较低的 `SQL` 语句，用-`-log-slow-queries[=file_name]`选项启动时，`mysqld` 写一个包含所有执行时间超过 `long_query_time` 秒的 `SQL` 语句的日志文件。
- 慢查询日志在查询结束以后才纪录， 所以在应用反映执行效率出现问题的时候查询慢查 询日志并不能定位问题， 可以使用==show processlist==命令查看当前`MySQL`在进行的线程， 包括线程的状态、是否锁表等，可以实时地查看 `SQL` 的执行情况，同时对一些锁表操 作进行优化。

### 3[.通过 EXPLAIN 分析低效 SQL 的执行计划](https://blog.csdn.net/lilongsy/article/details/95184594?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param)

通过以上步骤查询到效率低的 `SQL` 语句后， 可以通过 `EXPLAIN` 或者 `DESC`命令获取 `MySQL` 如何执行 `SELECT` 语句的信息，包括在 `SELECT` 语句执行过程中表如何连接和连接的顺序，比如想计算 `2006` 年所有公司的销售额，需要关联 `sales` 表和 `company` 表，并且对 `moneys` 字段 做求和（`sum`）操作，相应 `SQL` 的执行计划如下：

```mysql
mysql> explain select sum(moneys) from sales a,company b where a.company_id = b.id and a.year = 2006\G;
*************************** 1. row ***************************
	       id: 1
  select_type: SIMPLE
	    table: a
	     type: ALL
possible_keys: NULL
		  key: NULL
	  key_len: NULL
		  ref: NULL
		 rows: 1000
		Extra: Using where
*************************** 2. row ***************************
           id: 1
  select_type: SIMPLE
        table: b
         type: ref
possible_keys: ind_company_id
          key: ind_company_id
      key_len: 5
          ref: sakila.a.company_id
	     rows: 1
	    Extra: Using where; Using index
2 rows in set (0.00 sec)
123456789101112131415161718192021222324
```

每个列的简单解释如下：

* `id`：代表select子句或者是操作表的顺序
  * id相同，表示加载表的顺序是从上到下（例如连表查询 select * from user ,role where user.id = role.id）
  * id不同，id值越大，优先级越高，越先被执行（例如嵌套子查询 selelct * from user where id = (select id)）
  * 同时存在id相同和不同

- `select_type`：表示 `SELECT` 的类型，常见的取值有 `SIMPLE`（简单表，即不使用表连接 或者子查询） 、`PRIMARY`（主查询，即外层的查询） 、`Dervied`临时衍生表、`SUBQUERY`（子查询中的第一个 `SELECT`、`UNION`（`UNION` 中的第二个或 者后面的查询语句） ）等。
- `table`：输出结果集的表。
- `type`：表示表的连接类型，性能由好到差的连接类型为
  - null,例如select now():
  -  `system`（表中仅有一行，即 常量表） 、
  - `const`（通过索引一次就找到了，单表中最多有一个匹配行，例如 `primary key` 或者 `unique index`） 
  -  `eq_ref`（对于前面的每一行，在此表中只查询一条记录，简单来说，就是多表连接 中使用`primary key`或者`unique index`） 、
  -  `ref`（与`eq_ref`类似， 区别在于不是使用`primary key` 或者 `unique index`，而是使用普通的索引） 、`ref_or_null`（与 `ref` 类似，区别在于 条件中包含对 `NULL` 的查询） 、`index_merge`(索引合并优化)、`unique_subquery`（`in` 的后面是一个查询主键字段的子查询） 、 `index_subquery` （与 `unique_subquery` 类似， 区别在于 `in` 的后面是查询非唯一索引字段的子查询） 、
  -  `range` （单表中的范围查询） 、 
  - `index` （对于前面的每一行， 都通过查询索引来得到数据） 、
  -  `all` （对于前面的每一行， 都通过全表扫描来得到数据）
- `possible_keys`：表示查询时，可能使用的索引。
- `key`：表示实际使用的索引。
- `key_len`：索引字段的长度。
- ref:引用
- `rows`：扫描行的数量。
- `Extra`：执行情况的说明和描述。
  - using filesort:说明mysql会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取，称为文件排序
  - using temporary:使用了临时表保存中间结果，mysql在对查询结果排序时使用临时表，常见于order by，group by
  - using index：表示相应的select操作使用了覆盖索引（不需要回表查询），避免访问表的数据行，效率不错

### 4.确定问题并采取相应的优化措施

#### ptofile

> 查看表耗费时间

```cmd
#查看是否支持profiling
mysql> select @@have_profiling;
+------------------+
| @@have_profiling |
+------------------+
| YES              |
+------------------+
1 row in set (0.00 sec)
#查看是否开启profileing
mysql> select @@profiling；
+-------------+
| @@profiling |
+-------------+
|           0 |
+-------------+
1 row in set (0.00 sec)
#设置profiling为1
mysql> set @@profiling=1;
Query OK, 0 rows affected (0.00 sec)

mysql> select @@profiling;
+-------------+
| @@profiling |
+-------------+
|           1 |
+-------------+
1 row in set (0.00 sec)
#查看表耗时
mysql> show profiles;
+----------+------------+------------------------------+
| Query_ID | Duration   | Query                        |
+----------+------------+------------------------------+
|        1 | 0.00011925 | set @@profiling=1            |
|        2 | 0.00122275 | select @@profiling           |
|        3 | 0.00799600 | show databases               |
|        4 | 0.00051650 | SELECT DATABASE()            |
|        5 | 0.00120550 | show tables                  |
|        6 | 0.00491975 | select count(*) from student |
|        7 | 0.00365100 | select * from user           |
+----------+------------+------------------------------+
7 rows in set (0.00 sec)
# 查看查询id经历的阶段，以及耗时
mysql> show profile （cpu） for query 3;
+--------------------+----------+
| Status             | Duration |
+--------------------+----------+
| starting           | 0.000061 |
| Opening tables     | 0.002288 |
| System lock        | 0.000056 |
| init               | 0.000005 |
| optimizing         | 0.000002 |
| statistics         | 0.000007 |
| preparing          | 0.000005 |
| executing          | 0.005316 |
| Sending data       | 0.000023 |  //访问数据行并将结果返回到客户端
| end                | 0.000007 |
| query end          | 0.000002 |
| closing tables     | 0.000001 |
| removing tmp table | 0.000165 |
| closing tables     | 0.000004 |
| freeing items      | 0.000050 |
| logging slow query | 0.000001 |
| cleaning up        | 0.000003 |
+--------------------+----------+
17 rows in set (0.00 sec)

```

#### trace

> trace分析优化器

###### 在我们调优MySQL的SQL时候，通常使用explain进行查看sql的执行计划。至于优化器为什么会这样选择，就无从得知。如果你想了解为什么，那么可以通过trace文件能够进一步了解为什么优化器选择A执行计划而不选择B执行计划.帮助我们更好的理解优化器的行为.

###### 打开trace,并设置格式为Json

> SET OPTIMIZER_TRACE=“enabled=on”,END_MARKERS_IN_JSON=on;

###### 设置trace使用的内存大小,避免解析过程内存不足,文件显示不完整.

> SET OPTIMIZER_TRACE_MAX_MEM_SIZE=1000000;

###### 执行你的sql语句

> select * from a, b where a.id=b.sid;

###### 查看trace信息

> SELECT * FROM INFORMATION_SCHEMA.OPTIMIZER_TRACE;

###### TRACE json文件

```cmd
{
"steps": [
{
  "join_preparation": {  ---优化准备工作
    "select#": 1,
    "steps": [
      {
        "expanded_query": "/* select#1 */ select `a`.`id` AS `id`,`a`.`name` AS `name`,`a`.`age` AS `age`,`b`.`id` AS `id`,`b`.`sid` AS `sid`,`b`.`name` AS `name`,`b`.`score` AS `score` from `a` join `b` where (`a`.`id` = `b`.`sid`)"
      }
    ] /* steps */
  } /* join_preparation */
},
{
  "join_optimization": {---优化工作的主要阶段,包括逻辑优化和物理优化两个阶段
    "select#": 1,
    "steps": [---优化工作的主要阶段, 逻辑优化阶段  
      {
        "condition_processing": {  ---逻辑优化,条件化简  
          "condition": "WHERE",
          "original_condition": "(`a`.`id` = `b`.`sid`)",
          "steps": [
            {
              "transformation": "equality_propagation",  ---逻辑优化,条件化简,等式处理
              "resulting_condition": "(`a`.`id` = `b`.`sid`)"
            },
            {
              "transformation": "constant_propagation", ---逻辑优化,条件化简,常量处理
              "resulting_condition": "(`a`.`id` = `b`.`sid`)"
            },
            {
              "transformation": "trivial_condition_removal",  ---逻辑优化,条件化简,条件去除
              "resulting_condition": "(`a`.`id` = `b`.`sid`)"
            }
          ] /* steps */
        } /* condition_processing */
      }, ---逻辑优化,条件化简,结束 
      {
        "substitute_generated_columns": {
        } /* substitute_generated_columns */
      },
      {
        "table_dependencies": [ ---逻辑优化, 找出表之间的相互依赖关系. 非直接可用的优化方式.
          {
            "table": "`a`", ---表名
            "row_may_be_null": false, ---是否有null值，flase是没有
            "map_bit": 0,
            "depends_on_map_bits": [
            ] /* depends_on_map_bits */
          },
          {
            "table": "`b`",
            "row_may_be_null": false,
            "map_bit": 1,
            "depends_on_map_bits": [
            ] /* depends_on_map_bits */
          }
        ] /* table_dependencies */
      },
      {
        "ref_optimizer_key_uses": [ ---逻辑优化,  找出备选的索引  
          {
            "table": "`a`",  
            "field": "id", --索引字段
            "equals": "`b`.`sid`",  --连接的等值字段
            "null_rejecting": false
          },
          {
            "table": "`b`",
            "field": "sid",
            "equals": "`a`.`id`",
            "null_rejecting": false
          }
        ] /* ref_optimizer_key_uses */
      },
      {
        "rows_estimation": [  ---逻辑优化, 估算每个表的元组个数. 单表上进行全表扫描和索引扫描的代价估算. 每个索引都估算索引扫描代价  
          {
            "table": "`a`",
            "table_scan": { ---逻辑优化, 估算每个表的元组个数. 单表上进行全表扫描的代价
              "rows": 10,
              "cost": 1
            } /* table_scan */
          },
          {
            "table": "`b`",
            "table_scan": {
              "rows": 21,
              "cost": 1
            } /* table_scan */
          }
        ] /* rows_estimation */
      },
      {
        "considered_execution_plans": [  ---物理优化, 开始多表连接的物理优化计算
          {
            "plan_prefix": [
            ] /* plan_prefix */,
            "table": "`a`",
            "best_access_path": {
              "considered_access_paths": [
                {
                  "access_type": "ref",  ---物理优化, 计算indx_user索引上使用ref方查找的花费
                  "index": "PRIMARY",
                  "usable": false,
                  "chosen": false  ---物理优化, 本应该比较所有的可用索引,即打印出多个格式相同的但索引名不同的内容,这里却没有。推测是bug--没有遍历每一个索引. 
                },
                {
                  "rows_to_scan": 10,
                  "access_type": "scan",
                  "resulting_rows": 10,
                  "cost": 3,
                  "chosen": true
                }
              ] /* considered_access_paths */
            } /* best_access_path */,
            "condition_filtering_pct": 100,
            "rows_for_plan": 10,
            "cost_for_plan": 3,
            "rest_of_plan": [
              {
                "plan_prefix": [
                  "`a`"
                ] /* plan_prefix */,
                "table": "`b`",
                "best_access_path": {
                  "considered_access_paths": [
                    {
                      "access_type": "ref",
                      "index": "idx_sid",
                      "rows": 2.1,
                      "cost": 25.2,
                      "chosen": true
                    },
                    {
                      "rows_to_scan": 21,
                      "access_type": "scan",
                      "using_join_cache": true,
                      "buffers_needed": 1,
                      "resulting_rows": 21,
                      "cost": 43.006,
                      "chosen": false
                    }
                  ] /* considered_access_paths */
                } /* best_access_path */,
                "condition_filtering_pct": 100,
                "rows_for_plan": 21,
                "cost_for_plan": 28.2,
                "chosen": true
              }
            ] /* rest_of_plan */
          },
          {
            "plan_prefix": [
            ] /* plan_prefix */,
            "table": "`b`",
            "best_access_path": {
              "considered_access_paths": [
                {
                  "access_type": "ref",
                  "index": "idx_sid",
                  "usable": false,
                  "chosen": false
                },
                {
                  "rows_to_scan": 21,
                  "access_type": "scan",
                  "resulting_rows": 21,
                  "cost": 5.2,
                  "chosen": true
                }
              ] /* considered_access_paths */
            } /* best_access_path */,
            "condition_filtering_pct": 100,
            "rows_for_plan": 21,
            "cost_for_plan": 5.2,
            "rest_of_plan": [
              {
                "plan_prefix": [
                  "`b`"
                ] /* plan_prefix */,
                "table": "`a`",
                "best_access_path": {
                  "considered_access_paths": [
                    {
                      "access_type": "eq_ref",
                      "index": "PRIMARY",
                      "rows": 1,
                      "cost": 25.2,
                      "chosen": true,
                      "cause": "clustered_pk_chosen_by_heuristics"
                    },
                    {
                      "rows_to_scan": 10,
                      "access_type": "scan",
                      "using_join_cache": true,
                      "buffers_needed": 1,
                      "resulting_rows": 10,
                      "cost": 43.013,
                      "chosen": false
                    }
                  ] /* considered_access_paths */
                } /* best_access_path */,
                "condition_filtering_pct": 100,
                "rows_for_plan": 21,
                "cost_for_plan": 30.4,
                "pruned_by_cost": true
              }
            ] /* rest_of_plan */
          }
        ] /* considered_execution_plans */
      },
      {
        "attaching_conditions_to_tables": {
          "original_condition": "(`a`.`id` = `b`.`sid`)",
          "attached_conditions_computation": [
          ] /* attached_conditions_computation */,
          "attached_conditions_summary": [
            {
              "table": "`a`",
              "attached": null
            },
            {
              "table": "`b`",
              "attached": "(`a`.`id` = `b`.`sid`)"
            }
          ] /* attached_conditions_summary */
        } /* attaching_conditions_to_tables */
      },
      {
        "refine_plan": [
          {
            "table": "`a`"
          },
          {
            "table": "`b`",
            "pushed_index_condition": "(`a`.`id` = `b`.`sid`)",
            "table_condition_attached": null
          }
        ] /* refine_plan */
      }
    ] /* steps */
  } /* join_optimization */
},
{
  "join_execution": {
    "select#": 1,
    "steps": [
    ] /* steps */
  } /* join_execution */
}
] /* steps */
}
```



经过以上步骤，基本就可以确认问题出现的原因。此时用户可以根据情况采取相应的措施，进行优化提高执行的效率。

在上面的例子中，已经可以确认是对 a 表的全表扫描导致效率的不理想，那么对 `a` 表的 `year` 字段创建索引，具体如下：

```mysql
mysql> create index ind_sales2_year on sales2(year); 
Query OK, 1000 rows affected (0.03 sec) 
Records: 1000  Duplicates: 0  Warnings: 0 
123
```

创建索引后，再看一下这条语句的执行计划，具体如下：

```mysql
mysql> explain select sum(moneys) from sales a,company b where a.company_id = b.id and a.year = 2006\G;
*************************** 1. row ***************************
	       id: 1
  select_type: SIMPLE
	    table: a
	     type: ref
possible_keys: ind_sales2_year 
		  key: ind_sales2_year 
	  key_len: 2
		  ref: const
		 rows: 1
		Extra: Using where
*************************** 2. row ***************************
           id: 1
  select_type: SIMPLE
        table: b
         type: ref
possible_keys: ind_company2_id
          key: ind_company2_id
      key_len: 5
          ref: sakila.a.company_id
	     rows: 1
	    Extra: Using where; Using index
2 rows in set (0.00 sec)
123456789101112131415161718192021222324
```

可以发现建立索引后对 a 表需要扫描的行数明显减少 （从 `1000` 行减少到 `1` 行） ， 可见索引的 使用可以大大提高数据库的访问速度，尤其在表很庞大的时候这种优势更为明显。

## 2.索引问题

### 1. 索引的存储分类

`MyISAM` 存储引擎的表的数据和索引是自动分开存储的， 各自是独立的一个文件； `InnoDB` 存储引擎的表的数据和索引是存储在同一个表空间里面，但可以有多个文件组成。 `MySQL` 中索引的存储类型目前只有两种（`BTREE` 和 `HASH`） ，具体和表的存储引擎相关： `MyISAM` 和 `InnoDB` 存储引擎都只支持 `BTREE` 索引；`MEMORY/HEAP` 存储引擎可以支持 `HASH` 和 `BTREE` 索引。下面是创建前缀索引的一个例子：

```mysql
mysql> create index ind_company2_name on company2(name(4)); 
Query OK, 1000 rows affected (0.03 sec)
Records: 1000  Duplicates: 0  Warnings: 0
123
```

### 2. MySQL 如何使用索引

索引用于快速找出在某个列中有一特定值的行。对相关列使用索引是提高 `SELECT` 操作性能的最佳途径。

查询要使用索引最主要的条件是查询条件中需要使用索引关键字，如果是多列索引，那么只有查询条件使用了多列关键字最左边的前缀时， 才可以使用索引， 否则将不能使用索引。

### 2.1 使用索引

在 `MySQL` 中，下列几种情况下有可能使用到索引。

1. 对于创建的多列索引，只要查询的条件中用到了最左边的列，索引一般就会被使用， 举例说明如下。

   首先按 `company_id`，`moneys` 的顺序创建一个复合索引，具体如下：

   ```mysql
   mysql> create index ind_sales2_companyid_moneys on sales2(company_id,moneys); 
   Query OK, 1000 rows affected (0.03 sec) 
   Records: 1000  Duplicates: 0  Warnings: 0 
   123
   ```

   然后按 `company_id` 进行表查询，具体如下：

   ```mysql
   mysql> explain select * from sales2 where company_id = 2006\G; 
   *************************** 1. row *************************** 
              id: 1
     select_type: SIMPLE 
           table: sales2 
            type: ref 
   possible_keys: ind_sales2_companyid_moneys 
             key: ind_sales2_companyid_moneys 
         key_len: 5 
             ref: const 
            rows: 1 
           Extra: Using where 
    1 row in set (0.00 sec) 
   12345678910111213
   ```

   可以发现即便 `where` 条件中不是用的 `company_id` 与 `moneys` 的组合条件，索引仍然能用到，这就是索引的前缀特性。但是如果只按 `moneys` 条件查询表，那么索引就不会被用到，具体如下：

   ```mysql
   mysql> explain select * from company2 where name like '%3'\G; 
   *************************** 1. row *************************** 
              id: 1
     select_type: SIMPLE 
           table: sales2 
            type: ALL 
   possible_keys: NULL
             key: NULL
         key_len: NULL 
             ref: NULL
            rows: 1000 
           Extra: Using  where 
   1 row in set (0.00 sec) 
   12345678910111213
   ```

2. 对于使用 `like` 的查询，后面如果是常量并且只有`％`号不在第一个字符，索引才可能会被使用，来看下面两个执行计划：

   ```mysql
   mysql> explain select * from company2 where name like '%3'\G; 
              id: 1
     select_type: SIMPLE 
           table: company2 
            type: ALL 
   possible_keys: NULL
             key: NULL
         key_len: NULL 
             ref: NULL
            rows: 1000 
           Extra: Using  where 
   1 row in set (0.00 sec)
   
   mysql> explain select * from company2 where name like '3%'\G;  
   *************************** 1. row *************************** 
              id: 1
     select_type: SIMPLE 
           table: company2 
            type: range
   possible_keys: ind_company2_name 
             key: ind_company2_name 
         key_len: 11
             ref: NULL
            rows: 103
           Extra: Using where 
    1 row in set (0.00 sec) 
   1234567891011121314151617181920212223242526
   ```

   可以发现第一个例子没有使用索引，而第二例子就能够使用索引，区别就在于“`%`”的位置 不同，前者把“`%`”放到第一位就不能用到索引，而后者没有放到第一位就使用了索引。

   另外，如果如果 `like` 后面跟的是一个列的名字，那么索引也不会被使用。

3. 如果对大的文本进行搜索，使用全文索引而不用使用 `like ‘%...%’`。

4. 如果列名是索引，使用 `column_name is null` 将使用索引。如下例中查询 `name` 为 `null` 的记录就用到了索引:

   ```mysql
   mysql> explain select * from company2 where name is null\G; 
   *************************** 1. row *************************** 
   	       id: 1
     select_type: SIMPLE 
           table: company2 
            type: ref
   possible_keys: ind_company2_name 
             key: ind_company2_name 
         key_len: 11
             ref: const
            rows: 1
           Extra: Using where 
    1 row in set (0.00 sec) 
   12345678910111213
   ```

### 2.2 存在索引但不使用索引

在下列情况下，虽然存在索引，但是 `MySQL` 并不会使用相应的索引。

1. 如果 `MySQL` 估计使用索引比全表扫描更慢，则不使用索引。例如如果列 `key_part1` 均匀分布在 `1` 和 `100` 之间，下列查询中使用索引就不是很好：

   ```mysql
   SELECT * FROM table_name where key_part1 > 1 and key_part1 < 90; 
   1
   ```

2. 如果使用 `MEMORY/HEAP` 表并且 `where` 条件中不使用“`=`”进行索引列，那么不会用到索引。`heap` 表只有在“`=`”的条件下才会使用索引。

3. 用`or`分割开的条件， 如果`or`前的条件中的列有索引， 而后面的列中没有索引， 那么涉及到的索引都不会被用到，例如：

   ```mysql
   mysql> show index from sales\G; 
   *************************** 1. row *************************** 
          Table: sales 
     Non_unique: 1 
       Key_name: ind_sales_year 
   Seq_in_index: 1 
    Column_name: year
      Collation: A 
    Cardinality: NULL 
       Sub_part: NULL 
         Packed: NULL 
           Null:  
     Index_type: BTREE 
        Comment:  
   1 row in set (0.00 sec) 
   123456789101112131415
   ```

   从上面可以发现只有`year` 列上面有索引，来看如下的执行计划：

   ```mysql
   mysql> explain select * from sales where year = 2001 or country = 'China'\G; 
   *************************** 1. row *************************** 
   		   id: 1
     select_type: SIMPLE 
           table: sales 
            type: ALL
   possible_keys: ind_sales_year 
             key: NULL 
         key_len: NULL
             ref: NULL
            rows: 12
           Extra: Using where 
    1 row in set (0.00 sec) 
   12345678910111213
   ```

   可见虽然在`year`这个列上存在索引`ind_sales_year`， 但是这个`SQL`语句并没有用到这个索引， 原因就是 `or` 中有一个条件中的列没有索引。

4. 如果不是索引列的第一部分，如下例子:

   ```mysql
   mysql> explain select * from sales2 where moneys = 1\G; 
   *************************** 1. row *************************** 
   		   id: 1
     select_type: SIMPLE 
           table: sales2 
            type: ALL
   possible_keys: NULL 
             key: NULL 
         key_len: NULL
             ref: NULL
            rows: 1000
           Extra: Using where 
    1 row in set (0.00 sec) 	
   12345678910111213
   ```

   可见虽然在 `money` 上面建有复合索引，但是由于 `money` 不是索引的第一列，那么在查询中这个索引也不会被 `MySQL` 采用。

5. 如果 `like` 是以`％`开始，例如：

   ```mysql
   mysql> explain select * from company2 where name like '%3'\G; 
   *************************** 1. row *************************** 
   		   id: 1
     select_type: SIMPLE 
           table: company2 
            type: ALL
   possible_keys: NULL 
             key: NULL 
         key_len: NULL
             ref: NULL
            rows: 1000
           Extra: Using where 
    1 row in set (0.00 sec) 		
   12345678910111213
   ```

   可见虽然在 `name` 上建有索引，但是由于 `where` 条件中 `like` 的值的“`%`”在第一位了，那么 `MySQL` 也不会采用这个索引。

6. 如果列类型是字符串，那么一定记得在 `where` 条件中把字符常量值用引号引起来，否则的话即便这个列上有索引，`MySQL` 也不会用到的，因为，`MySQL` 默认把输入的常量值进行转换以后才进行检索。 如下面的例子中`company2`表中的`name`字段是字符型的， 但是 `SQL` 语句中的条件值 `294` 是一个数值型值，因此即便在 `name` 上有索引， `MySQL` 也不能 正确地用上索引，而是继续进行全表扫描。

   ```mysql
   mysql> explain select * from company2 where name = 294\G; 
   *************************** 1. row *************************** 
   		   id: 1
     select_type: SIMPLE 
           table: company2 
            type: ALL
   possible_keys: ind_company2_name 
             key: NULL 
         key_len: NULL
             ref: NULL
            rows: 1000
           Extra: Using where 
   1 row in set (0.00 sec) 
   
   mysql> explain select * from company2 where name = '294'\G; 
   *************************** 1. row *************************** 
   		   id: 1
     select_type: SIMPLE 
           table: company2 
            type: ref
   possible_keys: ind_company2_name 
             key: ind_company2_name 
         key_len: 23
             ref: const
            rows: 1
           Extra: Using where 
   1 row in set (0.00 sec) 
   123456789101112131415161718192021222324252627
   ```

   从上面的例子中可以看到，第一个 `SQL` 语句中把一个数值型常量赋值给了一个字符型的列 `name`，那么虽然在 `name` 列上有索引，但是也没有用到；而第二个 `SQL` 语句就可以正确使用索引。

### 3. 查看索引使用情况

如果索引正在工作，`Handler_read_key` 的值将很高，这个值代表了一个行被索引值读的次数，很低的值表明增加索引得到的性能改善不高，因为索引并不经常使用。

`Handler_read_rnd_next` 的值高则意味着查询运行低效，并且应该建立索引补救。这个值的含义是在数据文件中读下一行的请求数。如果正进行大量的表扫描， `Handler_read_rnd_next` 的值较高， 则通常说明表索引不正确或写入的查询没有利用索引， 具体如下。

```mysql
mysql> show status like 'Handler_read%'; 
+-----------------------+-------+ 
| Variable_name         | Value | 
+-----------------------+-------+ 
| Handler_read_first    | 0     | 
| Handler_read_key      | 5     | 
| Handler_read_next     | 0     | 
| Handler_read_prev     | 0     | 
| Handler_read_rnd      | 0     | 
| Handler_read_rnd_next | 2055  | 
+-----------------------+-------+ 
6 rows in set (0.00 sec) 
123456789101112
```

从上面的例子中可以看出，目前使用的 `MySQL` 数据库的索引情况并不理想。

## 3.简单优化方法

### 1. 定期分析表和检查表

分析表的语法如下：

```mysql
ANALYZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] ...  
```

本语句用于分析和存储表的关键字分布，分析的结果将可以使得系统得到准确的统计信 息，使得 `SQL` 能够生成正确的执行计划。如果用户感觉实际执行计划并不是预期的执行计 划，执行一次分析表可能会解决问题。在分析期间，使用一个读取锁定对表进行锁定。这对 于 `MyISAM`, `BDB` 和 `InnoDB` 表有作用。对于 `MyISAM` 表，本语句与使用 `myisamchk -a` 相当，下例中对表 `sales` 做了表分析：

```mysql
mysql> analyze table sales; 
+--------------+---------+----------+----------+ 
| Table        | Op      | Msg_type | Msg_text | 
+--------------+---------+----------+----------+ 
| sakila.sales | analyze | status   | OK       | 
+--------------+---------+----------+----------+ 
1 row in set (0.00 sec) 
1234567
```

检查表的语法如下：

```mysql
CHECK TABLE tbl_name [, tbl_name] ... [option] ... option = {QUICK | FAST | MEDIUM | EXTENDED | CHANGED}  
1
```

检查表的作用是检查一个或多个表是否有错误。 `CHECK TABLE`对`MyISAM`和`InnoDB`表有作用。 对于 `MyISAM` 表，关键字统计数据被更新，例如：

```mysql
mysql> check table sales; 
+--------------+-------+----------+----------+ 
| Table        | Op    | Msg_type | Msg_text | 
+--------------+-------+----------+----------+ 
| sakila.sales | check | status   | OK       | 
+--------------+-------+----------+----------+ 
1 row in set (0.00 sec) 
1234567
```

`CHECK TABLE` 也可以检查视图是否有错误，比如在视图定义中被引用的表已不存在，举例如下。

1. 首先我们创建一个视图。

   ```mysql
   mysql> create view sales_view3 as select *  from sales3; 
   Query OK, 0 rows affected (0.00 sec) 
   12
   ```

2. 然后 `CHECK` 一下该视图，发现没有问题。

   ```mysql
   mysql> check table sales_view3; 
   +--------------------+-------+----------+----------+ 
   | Table              | Op    | Msg_type | Msg_text | 
   +--------------------+-------+----------+----------+ 
   | sakila.sales_view3 | check | status   | OK       | 
   +--------------------+-------+----------+----------+ 
   1 row in set (0.00 sec) 
   1234567
   ```

3. 现在删除掉视图依赖的表。

   ```mysql
   mysql> drop table sales3; 
   Query OK, 0 rows affected (0.00 sec) 
   12
   ```

4. 再来 `CHECK` 一下刚才的视图，发现报错了。

   ```mysql
   mysql> check table sales_view3\G; 
   *************************** 1. row *************************** 
      Table: sakila.sales_view3 
         Op: check 
   Msg_type: error 
   Msg_text: View 'sakila.sales_view3' references invalid table(s) or column(s) or function(s) or definer/invoker of view lack rights to use them 
   1 row in set (0.00 sec) 
   1234567
   ```

### 2. 定期优化表

优化表的语法如下：

```mysql
OPTIMIZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] ... 
1
```

如果已经删除了表的一大部分，或者如果已经对含有可变长度行的表（含有 `VARCHAR`、 `BLOB` 或 `TEXT` 列的表）进行了很多更改，则应使用 `OPTIMIZE TABLE` 命令来进行表优化。这个 命令可以将表中的空间碎片进行合并， 并且可以消除由于删除或者更新造成的空间浪费， 但 `OPTIMIZE TABLE` 命令只对 `MyISAM`、`BDB` 和 `InnoDB` 表起作用。

以下例子显示了优化表 `sales` 的过程：

```mysql
mysql> optimize table sales; 
+--------------+----------+----------+----------+ 
| Table        | Op       | Msg_type | Msg_text | 
+--------------+----------+----------+----------+ 
| sakila.sales | optimize | status   | OK       | 
+--------------+----------+----------+----------+ 
1 row in set (0.00 sec) 
```

## 4.常用Sql优化

### 1. 大批量插入数据

当用 `load` 命令导入数据的时候，适当的设置可以提高导入的速度。

对于 `MyISAM` 存储引擎的表，可以通过以下方式快速的导入大量的数据。

```mysql
ALTER TABLE tbl_name DISABLE KEYS; 
loading the data 
ALTER TABLE tbl_name ENABLE KEYS; 
123
```

`DISABLE KEYS` 和 `ENABLE KEYS` 用来打开或者关闭 `MyISAM` 表非唯一索引的更新。在导入大量的数据到一个非空的 `MyISAM` 表时，通过设置这两个命令，可以提高导入的效率。对于导入大量数据到一个空的 `MyISAM` 表，默认就是先导入数据然后才创建索引的，所以不用进行设置。

上面是对`MyISAM`表进行数据导入时的优化措施，对于`InnoDB`类型的表，这种方式并不能提高导入数据的效率，可以有以下几种方式提高`InnoDB`表的导入效率。

1. 因为 `InnoDB`类型的表是按照主键的顺序保存的，所以将导入的数据按照**主键的顺序**排列，可以有效地提高导入数据的效率。

   例如，下面文本`film_test3.txt`是按表`film_test4`的主键存储的，那么导入的时候共耗时 `27.92`秒。

   ```mysql
   mysql> load data infile '/home/mysql/film_test3.txt' into table film_test4; 
   Query OK, 1587168 rows affected (22.92 sec) 
   Records: 1587168  Deleted: 0  Skipped: 0  Warnings: 0 
   123
   ```

   而下面的 `film_test4.txt` 是没有任何顺序的文本，那么导入的时候共耗时 `31.16`秒。

   ```mysql
   mysql> load data infile '/home/mysql/film_test4.txt' into table film_test4; 
   Query OK, 1587168 rows affected (31.16 sec) 
   Records: 1587168  Deleted: 0  Skipped: 0  Warnings: 0 
   123
   ```

2. 在导入数据前执行 `SET UNIQUE_CHECKS=0`，关闭唯一性校验，在导入结束后执行 `SET UNIQUE_CHECKS=1`，恢复唯一性校验，可以提高导入的效率。省得插入的时候对比是否字段唯一

   例如，当 `UNIQUE_CHECKS=1`时：

   ```mysql
   mysql> load data infile '/home/mysql/film_test3.txt' into table film_test4; 
   Query OK, 1587168 rows affected (22.92 sec) 
   Records: 1587168  Deleted: 0  Skipped: 0  Warnings: 0 
   123
   ```

   当 `SET UNIQUE_CHECKS=0`时：

   ```mysql
   mysql> load data infile '/home/mysql/film_test3.txt' into table film_test4; 
   Query OK, 1587168 rows affected (19.92 sec) 
   Records: 1587168  Deleted: 0  Skipped: 0  Warnings: 0 
   123
   ```

3. 如果应用使用自动提交的方式，建议在导入前执行 `SET AUTOCOMMIT=0`，关闭自动提交，导入结束后再执行 `SET AUTOCOMMIT=1`，打开自动提交，也可以提高导入的效率。

   例如，当 `AUTOCOMMIT=1`时：

   ```mysql
   mysql> load data infile '/home/mysql/film_test3.txt' into table film_test4; 
   Query OK, 1587168 rows affected (22.92 sec) 
   Records: 1587168  Deleted: 0  Skipped: 0  Warnings: 0 
   123
   ```

   当 `AUTOCOMMIT=0`时：

   ```mysql
   mysql> load data infile '/home/mysql/film_test3.txt' into table film_test4; 
   Query OK, 1587168 rows affected (20.87 sec) 
   Records: 1587168  Deleted: 0  Skipped: 0  Warnings: 0 
   123
   ```

### 2. 优化 INSERT 语句

当进行数据`INSERT`的时候，可以考虑采用以下几种优化方式。

- 如果同时从同一客户插入很多行，尽量使用多个值表的`INSERT`语句，这种方式将大大缩减客户端与数据库之间的连接、关闭等消耗，使得效率比分开执行的单个`INSERT`语 快(在一些情况中几倍)。下面是一次插入多值的一个例子：

  ```mysql
  insert into test values(1,2),(1,3),(1,4)... 
  ```
  
- 在事务中进行数据插入

- 数据有序插入，按照主键顺序

- 如果从不同客户插入很多行，能通过使用`INSERT DELAYED`语句得到更高的速度。 `DELAYED`的含义是让`INSERT`语句马上执行，其实数据都被放在内存的队列中，并没有真正写入磁盘，这比每条语句分别插入要快的多；`LOW_PRIORITY`刚好相反，在所有其 他用户对表的读写完后才进行插入

- 将索引文件和数据文件分在不同的磁盘上存放（利用建表中的选项）

- 如果进行批量插入，可以增加`bulk_insert_buffer_size`变量值的方法来提高速度，但是， 这只能对`MyISAM`表使用；

- 当从一个文本文件装载一个表时，使用`LOAD DATA INFILE`。这通常比使用很多`INSERT`语句快`20`倍。

### 3. 优化 GROUP BY 语句

默认情况下，`MySQL`对所有`GROUP BY col1，col2....`的字段进行排序。这与在查询中指定 `ORDER BY col1，col2...`类似。因此，如果显式包括一个包含相同的列的`ORDER BY`子句，则对`MySQL`的实际执行性能没有什么影响。

如果查询包括`GROUP BY`但用户想要避免排序结果的消耗，则可以指定`ORDER BY NULL` 禁止排序，如下面的例子：

* using temperary

```mysql
mysql> explain select id,sum(moneys) from sales2 group by id\G; 
*************************** 1. row *************************** 
           id: 1 
  select_type: SIMPLE 
        table: sales2 
         type: ALL 
possible_keys: NULL 
          key: NULL 
      key_len: NULL 
          ref: NULL 
         rows: 1000 
        Extra: Using temporary; Using filesort 
1 row in set (0.00 sec) 

mysql> explain select id,sum(moneys) from sales2 group by id order by null\G; 
*************************** 1. row *************************** 
           id: 1 
  select_type: SIMPLE 
        table: sales2 
         type: ALL 
possible_keys: NULL 
          key: NULL 
      key_len: NULL 
          ref: NULL 
         rows: 1000 
        Extra: Using temporary; 
1 row in set (0.00 sec) 
123456789101112131415161718192021222324252627
```

从上面的例子可以看出第一个`SQL`语句需要进行 “`filesort`” ， 而第二个`SQL`由于`ORDER BY NULL` 不需要进行“`filesort`” ，而`filesort`往往非常耗费时间。

### 4. 优化 ORDER BY 语句

在某些情况中， `MySQL`可以使用一个索引来满足`ORDER BY`子句， 而不需要额外的排序。 `WHERE`条件和`ORDER BY`使用相同的索引，并且`ORDER BY`的顺序和索引顺序相同，并且 `ORDER BY`的字段都是升序或者都是降序。

* 通过返回数据进行排序，filesort排序，不适用索引的情况下
* 通过有序索引顺序扫描直接返回有序数据，using index，不需要额外排序，效率高。这种情况下返回的数据要为覆盖索引里面的字段或者主键，否则要回表进行查询，此时使用filesort排序

例如，下列SQL可以使用索引。

```mysql
SELECT * FROM t1 ORDER BY key_part1,key_part2,... ; 
SELECT * FROM t1 WHERE key_part1=1 ORDER BY key_part1 DESC, key_part2 DESC; 
SELECT * FROM t1 ORDER BY key_part1 DESC, key_part2 DESC; 
123
```

但是在以下几种情况下则不使用索引：

```mysql
#又使用升序又使用降序，则会导致不使用索引
SELECT * FROM t1 ORDER BY key_part1 DESC, key_part2 ASC；  
--order by的字段混合ASC和DESC 
SELECT * FROM t1 WHERE key2=constant ORDER BY key1；  
--用于查询行的关键字与ORDER BY中所使用的不相同 
SELECT * FROM t1 ORDER BY key1, key2；  
--对不同的关键字使用ORDER BY： 
123456
```

* 两次扫描算法和一次扫描算法（默认）

### 5. 优化嵌套查询

`MySQL 4.1`开始支持`SQL`的子查询。这个技术可以使用`SELECT`语句来创建一个单列的查询结果，然后把这个结果作为过滤条件用在另一个查询中。使用子查询可以一次性地完成很 多逻辑上需要多个步骤才能完成的SQL操作，同时也可以避免事务或者表锁死，并且写起 来也很容易。但是，有些情况下，子查询可以被更有效率的连接（`JOIN`）替代。

* 使用子查询需要在内存中 创建临时表，性能较低。同时通过in为一条一条判断，为index索引。性能低
* 推荐多表联查替换子查询，type为ref

在下面的例子中， 要从`sales2`表中找到那些在`company2`表中不存在的所有公司的信息：

```mysql
mysql> explain select * from sales2 where company_id not in ( select id from company2 )\G; 
*************************** 1. row *************************** 
           id: 1 
  select_type: PRIMARY 
        table: sales2 
         type: ALL 
possible_keys: NULL 
          key: NULL 
      key_len: NULL 
          ref: NULL 
         rows: 1000 
        Extra: Using where
*************************** 2. row *************************** 
           id: 2
  select_type: DEPENDENT SUBQUERY  
        table: company2 
         type: index_subquery 
possible_keys: ind_company2_id 
          key: ind_company2_id 
      key_len: 5
          ref: func 
         rows: 2 
        Extra: Using index
2 rows in set (0.00 sec) 
123456789101112131415161718192021222324
```

如果使用连接（`JOIN`）来完成这个查询工作，速度将会快很多。尤其是当`company2`表中对id建有索引的话，性能将会更好，具体查询如下：

```mysql
mysql> explain select * from sales2 left join company2 on sales2.company_id = company2.id where sales2.company_id is null\G; 
*************************** 1. row *************************** 
           id: 1 
  select_type: SIMPLE 
        table: sales2 
         type: ref 
possible_keys: ind_sales2_companyid_moneys 
          key: ind_sales2_companyid_moneys 
      key_len: 5 
          ref: const 
         rows: 1 
        Extra: Using where
*************************** 2. row *************************** 
           id: 1
  select_type: SIMPLE
        table: ref
         type: index_subquery 
possible_keys: ind_company2_id 
          key: ind_company2_id 
      key_len: 5
          ref: sakila.sales2.company_id 
         rows: 2 
        Extra:
2 rows in set (0.00 sec) 
123456789101112131415161718192021222324
```

从执行计划中可以明显看出查询扫描的记录范围和使用索引的情况都有了很大的改善。 连接（`JOIN`）之所以更有效率一些，是因为`MySQL` 不需要在内存中创建临时表来完成这个逻辑上的需要两个步骤的查询工作。

### 6.  优化 OR 条件

对于含有 `OR` 的查询子句， 如果要利用索引， 则 `OR` 之间的每个条件列都必须用到索引； 如果没有索引，则应该考虑增加索引。or不会使用复合索引。推荐union替换or。

```
select * from where id = 1 union select * from where id = 10;
```

### 7.优化分页查询

```
select * from tb limit 1000,10;查询从1000行开始的十条数据，此时mysql需要排序前1010条数据，仅仅返回1000-1010条记录，其他记录丢弃，查询排序的代价非常大。走全表扫描，不使用索引
优化思路一：完成排序分页后，根据主键关联回原表查询所需要的其他列内容
即先根据主键分页查询，用到了主键索引，插叙效率更高
select * from tb,(select * from tb order by id limit 1000,10) a where t.id=a.id
优化思路二：仅适用于主键自增的表且不能出现短层，可以把limit查询转换成某个位置的查询
select * from tb where id>20000 limit 10;
```

### 8. 使用 SQL 提示

`SQL` 提示（`SQL HINT`）是优化数据库的一个重要手段，简单来说就是在 `SQL` 语句中加入一些 人为的提示来达到优化操作的目的。

下面是一个使用 `SQL` 提示的例子：

```mysql
SELECT SQL_BUFFER_RESULTS * FROM... 
```

这个语句将强制 `MySQL` 生成一个临时结果集。只要临时结果集生成后，所有表上的锁定均被释放。 这能在遇到表锁定问题时或要花很长时间将结果传给客户端时有所帮助，因为 可以尽快释放锁资源。

下面是一些在 `MySQL` 中常用的 `SQL` 提示。

#### 8.1 USE INDEX

在查询语句中表名的后面，添加 `USE INDEX` 来提供希望 `MySQL` 去参考的索引列表，就可以让 `MySQL` 不再考虑其他可用的索引。

```mysql
mysql> explain select * from sales2 use index (ind_sales2_id) where id = 3\G; 
*************************** 1. row *************************** 
           id: 1 
  select_type: SIMPLE 
        table: sales2 
         type: ref
possible_keys: ind_sales2_id 
          key: ind_sales2_id 
      key_len: 5 
          ref: const 
         rows: 1
        Extra: Using where 
1 row in set (0.00 sec) 
12345678910111213
```

#### 8.2 IGNORE INDEX

如果用户只是单纯地想让 `MySQL` 忽略一个或者多个索引，则可以使用 `IGNORE INDEX` 作 为 `HINT`。同样是上面的例子，这次来看一下查询过程忽略索引 `ind_sales2_id`的情况：

```mysql
mysql> explain select * from sales2 ignore index (ind_sales2_id) where id = 3\G; 
*************************** 1. row *************************** 
           id: 1 
  select_type: SIMPLE 
        table: sales2 
         type: ALL
possible_keys: NULL 
          key: NULL 
      key_len: NULL 
          ref: NULL 
         rows: 1000
        Extra: Using where 
1 row in set (0.00 sec) 
12345678910111213
```

从执行计划可以看出，系统忽略了指定的索引，而使用了全表扫描

#### 8.3 FORCE INDEX

为强制 `MySQL` 使用一个特定的索引，可在查询中使用 `FORCE INDEX` 作为 `HINT`。例如， 当不强制使用索引的时候，因为 `id` 的值都是大于 `0` 的，因此 `MySQL` 会默认进行全表扫描， 而不使用索引，如下所示：

```mysql
mysql> explain select * from sales2 where id  > 0 \G; 
*************************** 1. row *************************** 
           id: 1 
  select_type: SIMPLE 
        table: sales2 
         type: ALL
possible_keys: ind_sales2_id 
          key: NULL 
      key_len: NULL 
          ref: NULL 
         rows: 1000
        Extra: Using where 
1 row in set (0.00 sec) 
12345678910111213
```

但是，当使用`FORCE INDEX` 进行提示时，即便使用索引的效率不是最高，`MySQL` 还是选择使用了索引，这是 `MySQL` 留给用户的一个自行选择执行计划的权力。加入 `FORCE INDEX` 提示后再次执行上面的 `SQL`：

```mysql
mysql> explain select * from sales2 force index (ind_sales2_id) where id > 0 \G; 
*************************** 1. row *************************** 
           id: 1 
  select_type: SIMPLE 
        table: sales2 
         type: range
possible_keys: ind_sales2_id 
          key: ind_sales2_id 
      key_len: 5 
          ref: NULL 
         rows: 1000
        Extra: Using where 
1 row in set (0.00 sec) 
```

### 9.模糊查询优化

​	有时候我们使用模糊查询（like）的时候，会出现索引失效的情况，比如根据手机号码后四位模糊匹配查询。在MySQL中模糊查询：mobile like ‘%8765’，这种情况是不能使用 mobile 上的索引的，那么如果需要根据手机号码后四位进行模糊查询，可以用一下方法进行改造。

    我们可以加入冗余列（MySQL5.7之后加入了虚拟列，使用虚拟列更合适，思路相同），比如 mobile_reverse，内部存储为 mobile 的倒叙文本，如 mobile 17312345678（手机号码为虚构），那么 mobile_reverse 存储 87654321371，为 mobile_reverse 列建立索引，查询中使用语句 mobile_reverse like reverse(’%5678’) 即可。

    reverse 是 MySQL 中的反转函数，这条语句相当于 mobile_reverse like ‘8765%’ ，这种语句是可以使用索引的。

    mobile_reverse 的更新可以用触发器解决，为表新建 ’新增‘和’更新‘的触发器，写入以下文本即可。

```sql
set new.mobile_reverse = REVERSE(new.mobile);
```

未改造前模糊查询语句为：

```sql
select * from xxx where mobile like '%5678';
```

改造后查询语句为：

```sql
select * from xxx where mobile_reverse like reverse('%5678');
```

或者

```sql
select * from xxx where mobile_reverse like '8765%';
```

改造后的模糊匹配可以使用 mobile_reverse 字段上的索引，加快查询速度。

## 5.索引失效

> 复合索引的创建

CREATE INDEX (自定义)索引名 ON 数据表(字段1name，字段2status，字段3address。。。);

* 全值匹配，索引中所有列都指定具体值，例如字段2=xx，字段1=xx
* 最左前缀匹配：如果索引多列，查询从最左前列开始，并且不跳过索引中的列。例如只根据字段1，字段3查询，跳过字段2，则走索引只根据字段1查询，字段3使用不到。其次如果根据字段2，字段3查询，则查询不到，不走索引。根据索引长度可以看出用了哪些索引。

* 范围查询右边的列，右边的列不会使用索引。> <

* 尽量使用覆盖索引，避免select* 。select* 需要回表查询，而使用覆盖索引避免回表查询

  ```cmd
  explain 中 extra信息:
  	using index:使用覆盖索引出现
  	usin where：在查找索引的情况下，需要回表查询所需的数据
  	using index condition：查找使用了索引，但是需要回表查询数据
  	using index：using where 查找使用了索引，但是需要的数据都在索引列中能找到，所以不需要回查询数据
  ```

* 尽量使用符合索引， 因为使用一个复合索引，相当于创建多个索引：字段1，字段1+字段2，字段1+字段2+字段...。如果使用单列索引，查询多个字段，只会选择其中一个最优的字段使用（辨别度最高的，例如唯一索引）

> 其他情况

* 不要在索引列上进行运算操作，否则索引失效
* 字符串不加单引号，造成索引失效

* or语句前后没有同时使用索引。当or左右查询字段只有一个是索引，该索引失效，只有当or左右查询字段均为索引时，才会生效
* select* where name like%开头的like模糊查询，索引失效，此时可以通过覆盖索引来解决，如select 字段1，字段2 where 字段1like %。但是使用尾部模糊匹配，索引不会失效。
* 如果Mysql评估使用索引比全表更慢，则不适用索引，查询的数据占所有表数据多的时候，例如name=’西安‘，表中所有数据name几乎都为西安，那么就不走索引更快，
* 在索引列上使用 IS NULL 或 IS NOT NULL操作。此时需要判断，如果该字段都不为null，则不走索引，全表扫描。所有进行判断
* in走索引，not in索引失效

> 查看索引使用情况

```
show status like 'handler_read%'
show global status like ’handler_read%‘
```


## shard路由

> doc路由到shard

一个doc必定存在一个primary shard中

> 路由算法

shar=hash(routing)%number_of_primary_shards

假设一个index有3个primary shard，每次增删改查一个doc的时候，都会带过来一个routing number，默认就是doc的_id（可能手动指定，也有可能是自动生成）routing=\_id，然后将routing值传入hash函数中，产生一个routing的hash值，hash(routing)=21

将hash函数产生的值对这个index的primary shard的数量求余数，hash值对这个有3个primary shard的index求余，21%3==0，所以这个doc就存在p0中。相同的routing值，每次传过来，从hash函数中，产生的hash值一定是相同的，无论hash值是几，对numberOfPrimaryShards求余数，结果一定在0到numberOfPrimaryShards-1之间。

> _id 还是custom routing value

默认的routing就是id

也可以在发送请求的时候，手动指定一个routing value，比如说put /index/type/id?routing=userId

手动指定routing value是很有用的，可以保证某一类doc一定被路由到一个shard中，后续进行应用级别的负载均衡，以及提升批量读取性能时，有很大帮助。

> primary shard数量不可变的谜底

如果primary shard由3变为4，那么21%4=1，路由到p1，导致数据间接丢失

## doc增删改



1.注意点：primary shard可以增删改，replica shard只能查

2.当请求发送到任意一个节点（可以将其称为协调节点coordinating node），如id=1发送到节点A上，节点A会知道id=1的primary shard节点在哪，于是会进行分发至B

3.存在id=1节点primary shard的b节点进行修改之后，会将数据同步到replica shard C中，然后A协调节点将结果进行返回。（是否是A节点返回，还是replica shard节点返回）

## quorum机制



> consistency，one(primary shard),all(all shard),quorum(default)

在发送任何一个请求时，比如说put /index/type/id，都可以带上consistency参数，指明写一致性是什么

put /index/type/id>consistency=quorum

One:要求写操作，只要有一个primary shard是active活跃可行，就可以执行。这里个人理解是只要存在对应的primary shard是活跃才可执行，而不是任意一个primary shard

two:要求写操作，所有primary shard和replica shard都活跃才可执行

Quorum:默认值，要求写操作大部分shard可用，才可执行写操作

> quorum机制

必须确保大部分shard可用，即(primary shard+numberOfreplicas)/2+1,当numberOfreplicas>1时才生效

举个例子：primary shard=3，replica=1，则供6个shard，(3+1)/2+1=3，所以6个shard中至少有3个shard是active状态，才可以执行该操作。

若replica=5，则(3+5)/2+1=5,至少需要5个shard，而不是单纯primary shard均可用就可以执行。

> 若节点数少于quorum数量，可能导致quorum不齐全，将无法执行写操作。

若primary shard=1，replica=3，primary和repica不能在同一节点，又只有一个node，那么导致两replica丢失，此时quorum数量为

(1+3)/2+1=3，shard树小于quorum要求，不满足条件，es默认等待新shard增加，直到timeout

另外一种情况：numberOfreplicas>1时，quorum机制才生效，因为若replica=1，此时就一个primary shard，(1+1)/2+1=2，就必须有两个shard活跃才能使用，此时节点只有一个？不特殊处理，单节点无法使用。如果节点为2，则必须两个节点都完整才能使用？

> quorum不齐全时

timeout，默认一分钟,设定quorum不齐全的时候，es的timeout，这期间等待shard活跃数量增加。

put /index/type/id?timeout=30，时间默认为30ms



## es查询机制

注意查询请求，replica shard和primary shard均可以处理请求。

1.假设java程序访问到节点A进行4次查询，那么若将会使用round-robin随机轮询算法，将两次查询请求发送到节点B，两次查询结果请求到节点C，尽量让primary shard和所欧的replica shard均匀服务请求，得到负载均衡的效果。

2.实际的shard获取document之后返回给协调节点，协调节点将结果返回给java应用程序

3.存在一种情况，document正在建立索引，只有primary  shard存在，此时replica shard上没有，但是协调节点可能会将请求发送给replica shard，此时会找不到这个documetn，等待该doc完成建立索引的过程，primary shard和replica shard均存在。

## bulk格式讲解

### bulk格式

```
bulk格式格式一：
{"action":{"meta"}}\n
{"data"}
错误格式二：
[{"acition":{},"data":{}]}]
```

### 原因剖析

>  如果使用良好的json数组格式，允许任意的换行，可读性棒，但是要按照如下流程处理

1.json数组解析为JSONArray对象，此时整个数组会出现一份一模一样的拷贝，一份数据就是json文本，一份数据就是JSONArrya对象

2.解析jason数组里的每个json，对每个请求中的doc进行路由

3.为路由到同一个shard的多个请求，创建一个请求数组

4.为这个请求数组序列化

5.将序列化后的请求数组发送到对应节点上

> 格式二问题

主要原因：耗费内存大，jvm gc开销大

bulk size通常为几千条，大小在10MB左右。假设100个bulk请求发送到同一个节点中，10MB*100=1G，json再拷贝一份成jsonArray对象，内存占用翻倍，就会占用2GB内存，实际情况可能搞成其他数据结构，2GB+的内存占用，导致其他请求：搜索、分析性能急速下降，最后导致java虚拟机的垃圾回收次数更多，更频繁，每次要回收的垃圾对象更多，耗费时间更多，导致es的java虚拟机停止工作线程的时间更多。

> 格式一优点

处理流程

1.不用将其转化为json对象，导致内存中相同数据的拷贝，依照换行符切割json

2.对每两个一组的json，读取meta，进行document路由

3.将对应json发送到node中

## 查询原理

### 查询

```
GET http://192.168.0.120:9200/_search

HTTP/1.1 200 OK
content-type: application/json; charset=UTF-8

{
  "took": 127,  //搜索请求耗费时间
  "timed_out": false,
  "_shards": {   //请求发送到多少个shard中去，多少个成功，多少个失败，即便失败，也不会影响其他，可能在primary shar也可能在replica shard
    "total": 2,
    "successful": 2,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {   
      "value": 8,    //返回了多少条结果
      "relation": "eq"
    },
    "max_score": 1.0,  本次搜索请求最大相关度分数，doc与search相关度越相关，_score分数越大， 排位越靠前
    "hits": [
      {
        "_index": "test_index",
        "_type": "_doc",
        "_id": "8",
        "_score": 1.0,
        "_source": {
          "test_field": "test"
        }
      },
      {
        "_index": "test_index",
        "_type": "_doc",
        "_id": "10",
        "_score": 1.0,
        "_source": {
          "doc": {
            "test_field1": "test update1"
          }
        }
      },
      {
        "_index": "test_index",
        "_type": "_doc",
        "_id": "9",
        "_score": 1.0,
        "_source": {
          "test_field1": "test update1",
          "test_field2": "test2"
        }
      },
      {
        "_index": "test_index",
        "_type": "_doc",
        "_id": "1",
        "_score": 1.0,
        "_source": {
          "name": 0,
          "tags": []
        }
      },
      {
        "_index": "test_type",
        "_type": "_doc",
        "_id": "8",
        "_score": 1.0,
        "_source": {
          "test_field": "test varsion3"
        }
      },
      {
        "_index": "test_type",
        "_type": "_doc",
        "_id": "7",
        "_score": 1.0,
        "_source": {
          "test_field": "test 2"
        }
      },
      {
        "_index": "test_type",
        "_type": "_doc",
        "_id": "9",
        "_score": 1.0,
        "_source": {
          "doc": {
            "test_field1": "test update1"
          }
        }
      },
      {
        "_index": "test_type",
        "_type": "_doc",
        "_id": "10",
        "_score": 1.0,
        "_source": {
          "doc": {
            "test_field1": "test update10"
          }
        }
      }
    ]
  }
}

Response code: 200 (OK); Time: 222ms; Content length: 1011 bytes
```

### 超时

timeout：默认情况下没有所谓的timeout，指定timeout意思是

GET http://192.168.0.120:9200/_search?timeout=1ms. 也就是es内部只要在1ms查到的数据进行返回，

## Multi-index搜索

### 查询意义

/search：所有索引，所有type下的所有数据都搜索出来

/index/_search:指定一个index，搜索其下所有type数据

/index1,index2/_search:	多个索引下全部数据

```
###查询index，type类型索引
GET http://192.168.0.120:9200/test_index.test_type/_search
###查询以test开头的所有索引下的数据，按照统配符，匹配多个索引。
GET http://192.168.0.120:9200/test_*/_search
#搜索指定索引下，指定type类型的数据
GET http://192.168.0.120:9200/test_index1,test_index2/type1,type2/_search
#搜索所有index下指定type的数据
GET http://192.168.0.120:9200/_all/type2,type1/_search
```

### 查询原理

一个index可能分配到多个priamry shard中，因此 查询索引下所有数据，会将请求发送给所有的primary shard（或者对应replca shard）执行，每个shard包含部分数据。

## 分页查询

### 示例

```
###分页查询，结果from=0，size=2. 查询出两条结果，但是总命中为4
GET http://192.168.0.120:9200/test_index/_doc/_search?from=0&size=2
Content-Type: application/json

GET http://192.168.0.120:9200/test_index/_doc/_search?from=0&size=2

HTTP/1.1 200 OK
Warning: 299 Elasticsearch-7.8.0-757314695644ea9a1dc2fecd26d1a43856725e65 "[types removal] Specifying types in search requests is deprecated."
content-type: application/json; charset=UTF-8

{
  "took": 53,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 4,
      "relation": "eq"
    },
    "max_score": 1.0,
    "hits": [
      {
        "_index": "test_index",
        "_type": "_doc",
        "_id": "8",
        "_score": 1.0,
        "_source": {
          "test_field": "test"
        }
      },
      {
        "_index": "test_index",
        "_type": "_doc",
        "_id": "10",
        "_score": 1.0,
        "_source": {
          "doc": {
            "test_field1": "test update1"
          }
        }
      }
    ]
  }
}

Response code: 200 (OK); Time: 148ms; Content length: 367 bytes

```

### deep paging

含义：搜索的特别深，比如总共有60000条数据，总共3个primary shard，每个shard20000条数据。每页是10条数据，这个时候搜索到1000页，那么需要的是_score分数做高的10000-10010条数据。那么coordinate node将会从3个shard中获取10010条数据，总计30030条数据，然后进行汇总，这个过程十分耗费网络带宽和内存。所以应该尽量避免deep pagin	

## Query String

### 查询包含关键字

```
#查询test_field字段中包含test的数据
GET http://192.168.0.120:9200/test_type/_doc/_search?q=test_field:test
GET http://192.168.0.120:9200/test_type/_doc/_search?q=+test_field:test

GET http://192.168.0.120:9200/test_type/_doc/_search?q=+test_field%3Atest

HTTP/1.1 200 OK
Warning: 299 Elasticsearch-7.8.0-757314695644ea9a1dc2fecd26d1a43856725e65 "[types removal] Specifying types in search requests is deprecated."
content-type: application/json; charset=UTF-8

{
  "took": 2,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 2,
      "relation": "eq"
    },
    "max_score": 0.18232156,
    "hits": [
      {
        "_index": "test_type",
        "_type": "_doc",
        "_id": "8",
        "_score": 0.18232156,
        "_source": {
          "test_field": "test varsion3"
        }
      },
      {
        "_index": "test_type",
        "_type": "_doc",
        "_id": "7",
        "_score": 0.18232156,
        "_source": {
          "test_field": "test 2"
        }
      }
    ]
  }
}

Response code: 200 (OK); Time: 79ms; Content length: 378 bytes

```

### 查询不包含关键词

```
###query String,不含aa字段test_field的所有数据
GET http://192.168.0.120:9200/test_type/_doc/_search?q=-test_field:aa

GET http://192.168.0.120:9200/test_type/_doc/_search?q=-test_field%3Aaa

HTTP/1.1 200 OK
Warning: 299 Elasticsearch-7.8.0-757314695644ea9a1dc2fecd26d1a43856725e65 "[types removal] Specifying types in search requests is deprecated."
content-type: application/json; charset=UTF-8

{
  "took": 6,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 4,
      "relation": "eq"
    },
    "max_score": 0.0,
    "hits": [
      {
        "_index": "test_type",
        "_type": "_doc",
        "_id": "8",
        "_score": 0.0,
        "_source": {
          "test_field": "test varsion3"
        }
      },
      {
        "_index": "test_type",
        "_type": "_doc",
        "_id": "7",
        "_score": 0.0,
        "_source": {
          "test_field": "test 2"
        }
      },
      {
        "_index": "test_type",
        "_type": "_doc",
        "_id": "9",
        "_score": 0.0,
        "_source": {
          "doc": {
            "test_field1": "test update1"
          }
        }
      },
      {
        "_index": "test_type",
        "_type": "_doc",
        "_id": "10",
        "_score": 0.0,
        "_source": {
          "doc": {
            "test_field1": "test update10"
          }
        }
      }
    ]
  }
}

Response code: 200 (OK); Time: 86ms; Content length: 581 bytes

```

### 所有索引查询

```
###查询包含version的数据，如果field3中存的是abc field将无法查出来	
GET http://192.168.0.120:9200/test_type/_doc/_search?q=version

HTTP/1.1 200 OK
Warning: 299 Elasticsearch-7.8.0-757314695644ea9a1dc2fecd26d1a43856725e65 "[types removal] Specifying types in search requests is deprecated."
content-type: application/json; charset=UTF-8

{
  "took": 4,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 1,
      "relation": "eq"
    },
    "max_score": 0.2876821,
    "hits": [
      {
        "_index": "test_type",
        "_type": "_doc",
        "_id": "1",
        "_score": 0.2876821,
        "_source": {
          "field3": "version"
        }
      }
    ]
  }
}

Response code: 200 (OK); Time: 86ms; Content length: 263 bytes
```

#### 思考

通过version查找数据，若存在多个field2，field1，那么是对doc中每个field进行一次搜索吗？

答案：不是。实际上field1：a ，field2：b，field3:c，那么es会将多个field值使用字符串的方式进行串联，变成一个长字符串，作为_all field的值，同时建立索引，如果在搜索的时候，没有对某个field指定搜索，就默认搜索\_al field，其中包含所有fieldl

## Mapping演示1

### 创建数据

```
###
PUT http://192.168.0.120:9200/website/aricle/1
Content-Type: application/json

{"post_date":"2017-01-01",
"title":"my first article",
"content":"this is my first article in this website",
"author_id":11400}

###
PUT http://192.168.0.120:9200/website/aricle/2
Content-Type: application/json

{"post_date":"2017-01-02",
  "title":"my second article",
  "content":"this is my second article in this website",
  "author_id":11400}

###
PUT http://192.168.0.120:9200/website/aricle/3
Content-Type: application/json

{"post_date":"2017-01-03",
  "title":"my third article",
  "content":"this is my third article in this website",
  "author_id":11400}
  
  
HTTP/1.1 201 Created
Location: /website/aricle/3
Warning: 299 Elasticsearch-7.8.0-757314695644ea9a1dc2fecd26d1a43856725e65 "[types removal] Specifying types in document index requests is deprecated, use the typeless endpoints instead (/{index}/_doc/{id}, /{index}/_doc, or /{index}/_create/{id})."
content-type: application/json; charset=UTF-8

{
  "_index": "website",
  "_type": "aricle",
  "_id": "3",
  "_version": 1,
  "result": "created",
  "_shards": {
    "total": 2,
    "successful": 1,
    "failed": 0
  },
  "_seq_no": 2,
  "_primary_term": 1
}

Response code: 201 (Created); Time: 128ms; Content length: 157 bytes

```

### 查看数据

```
### "post_date": "2017-01-01", 只有一条结果，按道理来说使用全文检索，应该有3条数据
GET http://192.168.0.120:9200/website/aricle/_search?q=2017

###  "post_date": "2017-01-03",   只有一条数据，但是此处在es5中可能存在多条数据
GET http://192.168.0.120:9200/website/aricle/_search?q=2017-01-02

###只有一条结果，因为精确匹配
GET http://192.168.0.120:9200/website/aricle/_search?q=post_date:2017-01-02

###只有一条结果，按道理来说，这里不应该有数据，因为es做了优化
GET http://192.168.0.120:9200/website/aricle/_search?q=post_date:2017
```



### mapping讲解

自动或者手动为index中的type建立的一种数据结构和相关配置，简称为maping

dynamic mapping：自动为我们建立index，以及type对应的mapping，mapping包含了每个filed对应的数据类型，以及如何分词等设置

可以手动创建数据之前，先创建index和type，以及type对应的mapping

mapping就是es插入数据？或者创建索引时候自动建立mapping，为不同field建立不同data type，不同的data type分词和搜索行为不一样，所以会出现_all field和post_date field效果不一致(在es7中这里一致？)

```
###获取mapping索引信息，在es
GET http://192.168.0.120:9200/website/_mapping

HTTP/1.1 200 OK
content-type: application/json; charset=UTF-8

{
  "website": {
    "mappings": {
      "properties": {
        "author_id": {
          "type": "long"
        },
        "content": {
          "type": "text",
          "fields": {
            "keyword": {
              "type": "keyword",
              "ignore_above": 256
            }
          }
        },
        "post_date": {
          "type": "date"
        },
        "title": {
          "type": "text",
          "fields": {
            "keyword": {
              "type": "keyword",
              "ignore_above": 256
            }
          }
        }
      }
    }
  }
}

Response code: 200 (OK); Time: 72ms; Content length: 265 bytes

```

### 精确匹配与全文搜索对比

#### exact value

即2017-01-01，搜索的时候，必须输入2017-01-01，才能搜索出来

#### full text

不是单纯匹配完整的一个词，而是对值进行拆分(分词)后进行匹配。

* 缩写，比如搜索cn可以搜索出来china
* 时态(格式转换)，比如搜索like，可以搜索出likes，liked，like
* 大小写，比如搜索tom，可以搜索出Tom
* 同义词，比如搜索love，可以搜索出lke

## 倒排核心

假设doc1:mother liked small dogs,

### 倒排索引建立

| 索引   | doc1 | Doc2 |
| ------ | ---- | ---- |
| mother | 存在 |      |
| liked  | 存在 |      |
| small  | 存在 |      |
| dogs   | 存在 |      |

此时假设搜索mother like little dog，虽然这些单词均不存在，但是es建立倒排索引时，会执行一个操作对拆分出的各个单词进行相应处理，以提升后面搜索到相关联文档概率

### noramalization过程

liked-->like,dogs-->dog,small-->little, mother-->mom

通过这样一个过程因此，可以通过另一种方式搜索到doc1

## 分词器

一段句子拆分成一个一个的单词i，并对每个单词进行normarlization(时态转换，单复数转换)，分词器

recall：召回率，搜索的时候，增加能够搜索到结果的数量

character filter：在一段文本分词之前，先进行预处理，比如常见过滤html标签<span>hello<span>等

Tokenizer:分词，hello you and me-->hello,you,and,me

token filter：详见精确匹配与全文搜索对比，缩写，时态，同义词的转换。

经历过上述步骤之后，才会建立真正的一个倒排索引

### 内置分词器介绍

Set the shape to semi-transparent by calling set_trans(5)

standard analyzer:set, the,shape,to,semi,transparent,by calling, set_transe,5  （默认分词器）

Simple analyzer:set, the,shape,to,semi,transparent,by ,calling, set,transe.  下划线的单词会进行拆分

whitespace analyzer:Set, the,shape,to,semi-transparent,by, calling, set_transe(5),相当于只根据空格拆分

Language analyzer:set,shape,semi,transpar, call, set_tran,5. 只根据特定单词进行拆分，比如部分单词to，the无意义抛弃

## Mapping进阶2

### 1.倒排索引建立

es建立倒排索引和查询时候会进行nomalization，例如将dogs转换成dog进行建立倒排索引，同样查询时候，dogs通过dog进行查询。

### 2.不同类型filed搜索方式不同

比如date可能使用精确搜索，_all:即不指定对应key，只搜索关键词，那么使用的是全文检索，即分词+normalization

### 3.Query String揭秘

date使用精确搜索，text使用全文检索

### 4.查看分词器

```
GET http://192.168.0.120:9200/_analyze
Content-Type: application/json

{"analyzer": "standard","text":"2017-01-01"}

GET http://192.168.0.120:9200/_analyze

HTTP/1.1 200 OK
content-type: application/json; charset=UTF-8

{
  "tokens": [
    {
      "token": "2017",
      "start_offset": 0,
      "end_offset": 4,
      "type": "<NUM>",
      "position": 0
    },
    {
      "token": "01",
      "start_offset": 5,
      "end_offset": 7,
      "type": "<NUM>",
      "position": 1
    },
    {
      "token": "01",
      "start_offset": 8,
      "end_offset": 10,
      "type": "<NUM>",
      "position": 2
    }
  ]
}

Response code: 200 (OK); Time: 179ms; Content length: 240 bytes

```

### 5.Query String疑问

在5.2版本及7.8版本有区别，比如下面两个例子

```
### "post_date": "2017-01-01", 只有一条结果，按道理来说此处使用全文检索，应该有3条数据
GET http://192.168.0.120:9200/website/aricle/_search?q=2017
###只有一条结果，按道理来说，这里不应该有数据，因为es做了优化
GET http://192.168.0.120:9200/website/aricle/_search?q=post_date:2017
```

### 6.核心内容

1.es里面插入数据，会自动建立索引，type以及对应mapping信息

2.mapping自动定义了每个field的数据类型

3.不同的数据类型(比如text，date)可能是exact value，有的是full text。

4.exact value：将整个值作为关键词建立到倒排索引中；full text：经历各种各样的处理，分词，normalization（时态转换，同义词转换，大小写转换等），进而建立到索引中

5.exact value和full text类型的filed决定搜索过来的时候，两种类型搜索行为不一致，会根建立倒排索引的行为保持一致，比如说exact value搜索时，直接按照整个值进行匹配。full text query string，则进行分词和normalization再去倒排索引中查询

6.es的dynamic mapping：让其自动建立mapping，包括自动设置数据类型，也可以提前手动创建index和type的mapping，自己对个股field进行设置，包括数据类型，索引行为，分词器等

## Dynamic mapping3

### 动态索引核心数据类型：

* string、  text。 hello world。 转换

* byte、short、interger、long。 123 转换成long。  1233.45转换成double

* bollean。true、false
* date。如 2017-01-01自动转换成date
* 可以获取mapping信息

## 自主建立mapping索引4

### es5方式

```
###建立website 的mapping
PUT http://192.168.0.120:9200/website
Content-Type: application/json

###此处第一个坑在于不应该有article，报错信息root mapping definition has unsupported parameters",如果想改变，则配置inclue_type_name:true，在es8中已经完全抛除该字段。
###第二个坑在于string在5.x版本引入text和keyword，其中keyword不适合做分词字段，搜索时候只能完全匹配。string还保留，到6.x版本就已经彻底移除string，“index”：“not_analyzered”只能是boolean变量false，不能是not_analyzered
{"mappings": {
  "article": {
    "properties": {
      "content":{
        "type": "string","analyzer": "english"
      },
      "post_date": {
        "type": "date"
      },
      "title": {
        "type": "string"
      },
      "author_id": {
        "type": "long"
      }
    }
  }
}
}


###
PUT http://192.168.0.120:9200/a
Content-Type: application/json

{
  "mappings": {
    "properties": {
      "content":{"type": "text"},
      "post_date": {"type": "date"},
      "title": {"type": "text","analyzer": "english"},
      "author_id": {"type": "long"},
      "publlisher_id": {"type": "text","index": "not_analyzed"}
    }
  }
}

```

### es7方式

```java
###建立website 的mapping
PUT http://192.168.0.120:9200/website
Content-Type: application/json

{"mappings": {
    "properties": {
      "content":{
        "type": "text","analyzer": "english"
      },
      "post_date": {
        "type": "date"
      },
      "title": {
        "type": "text"
      },
      "author_id": {
        "type": "long"
      }
    }
  }
}

返回结果		
  "acknowledged": true,
  "shards_acknowledged": true,
  "index": "website"
```

### 修改mapping

报错，不能对建立好的mapping进行修改

```
###
PUT http://192.168.0.120:9200/a
Content-Type: application/json

{
  "mappings": {
    "properties": {
      "author_id": {"type": "text"}
    }
  }
}


PUT http://192.168.0.120:9200/a

HTTP/1.1 400 Bad Request
content-type: application/json; charset=UTF-8

{
  "error": {
    "root_cause": [
      {
        "type": "resource_already_exists_exception",
        "reason": "index [a/ca7AxqF5QDm2AxLuInx4Mg] already exists",
        "index_uuid": "ca7AxqF5QDm2AxLuInx4Mg",
        "index": "a"
      }
    ],
    "type": "resource_already_exists_exception",
    "reason": "index [a/ca7AxqF5QDm2AxLuInx4Mg] already exists",
    "index_uuid": "ca7AxqF5QDm2AxLuInx4Mg",
    "index": "a"
  },
  "status": 400
}

Response code: 400 (Bad Request); Time: 97ms; Content length: 345 bytes

```

### 新增mapping

```
PUT http://192.168.0.120:9200/a/_mapping
Content-Type: application/json

{
    "properties": {
      "tags": {"type": "text"}
    }
  }
}
```

### 查询mapping

```
GET http://192.168.0.120:9200/b/_mapping

HTTP/1.1 200 OK
content-type: application/json; charset=UTF-8

{
  "b": {
    "mappings": {
      "properties": {
        "author_id": {
          "type": "long"
        },
        "content": {
          "type": "text"
        },
        "post_date": {
          "type": "date"
        },
        "publlisher_id": {
          "type": "text",
          "index": false
        },
        "tags": {
          "type": "text"
        },
        "title": {
          "type": "text",
          "analyzer": "english"
        }
      }
    }
  }
}

Response code: 200 (OK); Time: 85ms; Content length: 231 bytes
		
```

### 查询mapping字段

如果是keyword，则代表不分词，那么查询结果

```
PUT http://192.168.0.120:9200/b/_mapping
Content-Type: application/json

{
"properties": {
"new_field": {"type": "keyword"}
}
}

###类型为keyword的分词结果是整个单词
GET http://192.168.0.120:9200/b/_analyze
Content-Type: application/json

{
  "field": "new_field",
  "text": "my dogs abc"
}

GET http://192.168.0.120:9200/b/_analyze

HTTP/1.1 200 OK
content-type: application/json; charset=UTF-8

{
  "tokens": [
    {
      "token": "my dogs abc",
      "start_offset": 0,
      "end_offset": 11,
      "type": "word",
      "position": 0
    }
  ]
}

###
GET http://192.168.0.120:9200/b/_analyze

HTTP/1.1 200 OK
content-type: application/json; charset=UTF-8

{
  "tokens": [
    {
      "token": "my",
      "start_offset": 0,
      "end_offset": 2,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "dogs",
      "start_offset": 3,
      "end_offset": 7,
      "type": "<ALPHANUM>",
      "position": 1
    },
    {
      "token": "abc",
      "start_offset": 8,
      "end_offset": 11,
      "type": "<ALPHANUM>",
      "position": 2
    }
  ]
}

Response code: 200 (OK); Time: 76ms; Content length: 256 bytes
```

## 复杂动态索引

### 1.multivalue field

{"tags":["tag1","tag2"]}，建立索引时与string一致，数据类型不能混

意思是{"name":["jack","rose"]}，里面tag都是同一数据类型

### 2.empty field

null，[],[null]

### 3.object field		

address就是obj类型，其下面还有一个properties

#### 建立索引

```
###必须添加_doc，否则建立失败
PUT http://192.168.0.120:9200/company/_doc/1
Content-Type: application/json

{
  "address": {
    "contry": "china",
    "province": "guangdong",
    "city": "广州"
  },
  "name": "jack",
  "age": 26,
  "join_date": "2015-01-01"
}
PUT http://192.168.0.120:9200/company/_doc/1

HTTP/1.1 201 Created
Location: /company/_doc/1
content-type: application/json; charset=UTF-8

{
  "_index": "company",
  "_type": "_doc",
  "_id": "1",
  "_version": 1,
  "result": "created",
  "_shards": {
    "total": 2,
    "successful": 1,
    "failed": 0
  },
  "_seq_no": 0,
  "_primary_term": 1
}

Response code: 201 (Created); Time: 538ms; Content length: 155 bytes

```

#### 查看索引信息

```
GET http://192.168.0.120:9200/company/_mapping
GET http://192.168.0.120:9200/company/_mapping

HTTP/1.1 200 OK
content-type: application/json; charset=UTF-8

{
  "company": {
    "mappings": {
      "properties": {
        "address": {
          "properties": {
            "city": {
              "type": "text",
              "fields": {
                "keyword": {
                  "type": "keyword",
                  "ignore_above": 256
                }
              }
            },
            "contry": {
              "type": "text",
              "fields": {
                "keyword": {
                  "type": "keyword",
                  "ignore_above": 256
                }
              }
            },
            "province": {
              "type": "text",
              "fields": {
                "keyword": {
                  "type": "keyword",
                  "ignore_above": 256
                }
              }
            }
          }
        },
        "age": {
          "type": "long"
        },
        "join_date": {
          "type": "date"
        },
        "name": {
          "type": "text",
          "fields": {
            "keyword": {
              "type": "keyword",
              "ignore_above": 256
            }
          }
        }
      }
    }
  }
}

Response code: 200 (OK); Time: 86ms; Content length: 452 bytes
```

#### 上述数据对应索引

```
{

"name":[jack],

"age":[27],

"Join_date":[2017-01-01],

"Address.country":[china].

"address.provice":[guangdong],

"address.city":"Guangzhou"

}
```

#### 数组类型对应索引

> 数据

{"author":{

{"age":22,"name":"jack"},

{"age":23,"name":"rose"},

{"age":24,"name":"robbed"},

}}

> 索引结构

{"author.age":[22,23,24],

"Author.name":[jack,rose,roobbd]

}

从行式存储到列示存储

## 搜索

### 查询语法

一般不允许使用request body发送get请求，建议使用queryString。但是es觉得是通过get请求进行查询，所以允许request body	

```
###搜索索引下数据
GET http://192.168.0.120:9200/company/_search

###通过queryString方式，get发送分页请求
GET http://192.168.0.120:9200/test_index,test_index1/type1,type2/_search

###total.value=4.但是只返回1条数据
GET http://192.168.0.120:9200/test_index/_search?from=0&size=1

###通过get 请求带上request body 
GET http://192.168.0.120:9200/test_index/_search
Content-Type: application/json

{"from": 0,"size": 2}

###通过post
POST http://192.168.0.120:9200/test_index/_search
Content-Type: application/json

{"from": 0,"size": 2}
```

### DSL搜索

> 示例

```
###
GET http://192.168.0.120:9200/test_index/_search
Content-Type: application/json

{"query": {"match_all": {}}}
```

> 基本语法

```
{
  query_name:{
    argument:value,
    argument:value
  }
}
{
  query_name:{
    filed_name:{
      argument:value,
      argument:value
    }
  }
}
```

#### 数据

```
GET http://192.168.0.120:9200/test_type/_search

HTTP/1.1 200 OK
content-type: application/json; charset=UTF-8

{
  "took": 1,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 5,
      "relation": "eq"
    },
    "max_score": 1.0,
    "hits": [
      {
        "_index": "test_type",
        "_type": "_doc",
        "_id": "8",
        "_score": 1.0,
        "_source": {
          "test_field": "test varsion3"
        }
      },
      {
        "_index": "test_type",
        "_type": "_doc",
        "_id": "7",
        "_score": 1.0,
        "_source": {
          "test_field": "test 2"
        }
      },
      {
        "_index": "test_type",
        "_type": "_doc",
        "_id": "9",
        "_score": 1.0,
        "_source": {
          "doc": {
            "test_field1": "test update1"
          }
        }
      },
      {
        "_index": "test_type",
        "_type": "_doc",
        "_id": "10",
        "_score": 1.0,
        "_source": {
          "doc": {
            "test_field1": "test update10"
          }
        }
      },
      {
        "_index": "test_type",
        "_type": "_doc",
        "_id": "1",
        "_score": 1.0,
        "_source": {
          "field3": "version"
        }
      }
    ]
  }
}

Response code: 200 (OK); Time: 91ms; Content length: 674 bytes

```

#### 搜索

```
###无结果
GET http://192.168.0.120:9200/test_type/_search
Content-Type: application/json

{"query": {"match": {"test_field1": "test"}}}

###varsion3可以搜索到数据
GET http://192.168.0.120:9200/test_type/_search
Content-Type: application/json

{"query": {"match": {"test_field": "varsion3"}}}
```

#### 组合搜索

> 数据插入

```
PUT http://192.168.0.120:9200//website/_create/1
Content-Type: application/json

{
  "title": "my haddop article",
  "content": "es is very good",
  "author_id": 111
}
###
PUT http://192.168.0.120:9200/website/_doc/2
Content-Type: application/json

{
  "title": "my jvm article",
  "content": "jvm is very bad",
  "author_id": 333
}

###
GET http://192.168.0.120:9200/website/_search

###
PUT http://192.168.0.120:9200/website/_doc/3
Content-Type: application/json

{
  "title": "my jvm article",
  "content": "jvm is very bad",
  "author_id": 333
}
```

> 组合查找

* 必须查找
* 可以包含,如果只有should，则满足should才会返回
* 不包含

**查询**1

```
###
GET http://192.168.0.120:9200/website/_search
Content-Type: application/json

{
  "query": {
    "bool": {
      "must": [{"match":{"title": "elasticsearch"}}],
      "should": [{"match":{"content": "es"}}],
      "must_not": [{"match":{"author_id": 22}}]
    }
  }
}

GET http://192.168.0.120:9200/website/_search

HTTP/1.1 200 OK
content-type: application/json; charset=UTF-8

{
  "took": 2,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 1,
      "relation": "eq"
    },
    "max_score": 0.9808291,
    "hits": [
      {
        "_index": "website",
        "_type": "_doc",
        "_id": "2",
        "_score": 0.9808291,
        "_source": {
          "title": "my elasticsearch article",
          "content": "elasticsearch is very bad",
          "author_id": 222
        }
      }
    ]
  }
}

Response code: 200 (OK); Time: 92ms; Content length: 343 bytes

```

**查询2**

```
###只有满足其中一个条件，结果才会返回
GET http://192.168.0.120:9200/website/_search
Content-Type: application/json

{
  "query": {
    "bool": {
      "should": [{"match":{"content": "as"}},{"match":{"content": "ls"}}]
    }
  }
}
```

#### filter搜索

```
###这里must可以不加[]，因为只有一个json串
GET http://192.168.0.120:9200/company/_doc/_search
Content-Type: application/json

{"query": {
  "bool": {
    "must": [{"match": {"name": "zz"}}],
    "filter": {"range": {"age": {"gte": 29}}}
  }
}}
```

**filter和query对比**

> 差异

* filter仅仅是按照搜索条件过滤出需要的数据，不计算相关度分数，所以不影响排序结果
* query，会去计算每个doc相对于搜索条件的相关度，并按照相关度进行排序

> 使用建议

* 若进行搜索将最匹配搜索条件的数据先返回，那么用query
* 如果只是根据条件筛选出一部分数据，不关注排序，那么使用filter，或者不希望搜索条件影响doc排序结果，那么放在filter中

> 性能对比

* Filter:不需要计算相关度分数，不需要按照相关度分数排序，具有内置自动cache最常使用filter的数据
* query：需要计算相关度分数，按照分数进行排序，无法cache结果，对cpu性能浪费较高

## 字符串排序问题

1.详见创建mapping

2.创建mapping，使用title字段进行排序，但是涉及一个问题"first article"排序时因为会自动使用first进行排序，那么就会出问题。而我们希望使用的是first article进行排序，所以，创建mapping时候，使用fielddata=true，以便开启正排索引进行索引，使用index：false禁止分词，使用title.raw就可以实现期待的排序结果

> 分词排序

```
###使用title排序
{
  "query": {
    "match_all": {}
  },
  "sort": {
    "title": "desc"
  }
}

结果
{
"_index": "web",
"_type": "_doc",
"_id": "2",
"_score": null,
"_source": {
"title": "second article",
"content": "this is my second article",
"post_date": "2017-02-01",
"author_id": 120
},
"sort": [
"second"
]
}
```

> 不分词排序

```
{
  "query": {
    "match_all": {}
  },
  "sort": {
    "title.raw": "desc"
  }
}

{
"_index": "web",
"_type": "_doc",
"_id": "3",
"_score": null,
"_source": {
"title": "third article",
"content": "my third article",
"post_date": "2013-01-01",
"author_id": 130
},
"sort": [
"third article"   //核心区别
]
}
 
```

